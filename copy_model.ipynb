{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, Normalizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from datetime import datetime\n",
    "\n",
    "pd.options.display.max_columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('https://raw.githubusercontent.com/mkleinbort/Kaggle-COMPAS/main/train/X_train.csv', index_col='id')\n",
    "y_train = pd.read_csv('https://raw.githubusercontent.com/mkleinbort/Kaggle-COMPAS/main/train/y_train.csv', squeeze=True)\n",
    "X_test = pd.read_csv ('https://raw.githubusercontent.com/mkleinbort/Kaggle-COMPAS/main/test/X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = X_train\n",
    "train_df['target'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['all_priors'] = train_df[[\n",
    "    'juv_fel_count',\n",
    "    'juv_misd_count', \n",
    "    'juv_other_count',\n",
    "    'priors_count'\n",
    "]].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop redundant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = train_df.drop([\n",
    "    'name', 'first', 'last',\n",
    "    'date_of_birth', 'age',\n",
    "    'juv_fel_count',\n",
    "    'juv_misd_count',\n",
    "    'juv_other_count',\n",
    "    'priors_count'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove cases where c_jail_days are negative. This is bad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['c_jail_out'] = pd.to_datetime(train_df.c_jail_out)\n",
    "train_df['c_jail_in'] = pd.to_datetime(train_df.c_jail_in)\n",
    "\n",
    "\n",
    "train_df['c_jail_days'] = (train_df.c_jail_out - train_df.c_jail_in)\n",
    "train_df['c_jail_days'] = train_df['c_jail_days'] // np.timedelta64(1, \"D\")\n",
    "\n",
    "# remove rows where c_jail_days is null\n",
    "train_df.dropna(subset=[\"c_jail_days\"], inplace=True)\n",
    "\n",
    "# drop more date columns\n",
    "train_df = train_df.drop([\"c_jail_out\", \"c_jail_in\", \"type_of_assessment\", \"c_offense_date\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if the subject has previously recided\n",
    "train_df['has_r_jail_in'] = train_df['r_jail_in'].notna()\n",
    "\n",
    "# check if the are out after receeding\n",
    "train_df['has_r_jail_out'] = train_df['r_jail_out'].notna()\n",
    "\n",
    "# drop the r_jail_in and r_jail_out columns \n",
    "train_df = train_df.drop([\"r_jail_out\", \"r_jail_in\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove v_type of assessment since all occuring values are the same\n",
    "train_df = train_df.drop([\"v_type_of_assessment\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custody days\n",
    "train_df.dropna(subset=[\"target\"], inplace=True)\n",
    "\n",
    "train_df['out_custody'] = pd.to_datetime(train_df.out_custody)\n",
    "train_df['in_custody'] = pd.to_datetime(train_df.in_custody)\n",
    "\n",
    "train_df['custody_days'] = (train_df.out_custody - train_df.in_custody)\n",
    "train_df['custody_days'] = train_df['custody_days'] // np.timedelta64(1, \"D\")\n",
    "\n",
    "train_df.dropna(subset=[\"custody_days\"], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop([\"screening_date\", \"v_screening_date\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age_group</th>\n",
       "      <th>race</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>start</th>\n",
       "      <th>target</th>\n",
       "      <th>all_priors</th>\n",
       "      <th>c_jail_days</th>\n",
       "      <th>has_r_jail_in</th>\n",
       "      <th>has_r_jail_out</th>\n",
       "      <th>custody_days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>Male</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2013-09-23</td>\n",
       "      <td>2013-09-27</td>\n",
       "      <td>3</td>\n",
       "      <td>No-Recidivism</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>Male</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>0</td>\n",
       "      <td>No-Recidivism</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Female</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>79</td>\n",
       "      <td>No-Recidivism</td>\n",
       "      <td>2</td>\n",
       "      <td>79.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>Male</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "      <td>2013-10-04</td>\n",
       "      <td>2013-10-05</td>\n",
       "      <td>1</td>\n",
       "      <td>No-Recidivism</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>Male</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>M</td>\n",
       "      <td>2015-09-03</td>\n",
       "      <td>2015-09-14</td>\n",
       "      <td>1</td>\n",
       "      <td>No-Recidivism</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sex     age_group              race  days_b_screening_arrest  \\\n",
       "id                                                                      \n",
       "2677    Male  Less than 25         Caucasian                     -1.0   \n",
       "548     Male  Less than 25  African-American                     -1.0   \n",
       "56    Female  Less than 25  African-American                     -1.0   \n",
       "489     Male       25 - 45         Caucasian                      0.0   \n",
       "430     Male       25 - 45  African-American                     -1.0   \n",
       "\n",
       "     c_charge_degree in_custody out_custody  start         target  all_priors  \\\n",
       "id                                                                              \n",
       "2677               F 2013-09-23  2013-09-27      3  No-Recidivism           2   \n",
       "548                F 2013-06-16  2013-06-16      0  No-Recidivism           2   \n",
       "56                 F 2015-01-30  2015-01-31     79  No-Recidivism           2   \n",
       "489                M 2013-10-04  2013-10-05      1  No-Recidivism           2   \n",
       "430                M 2015-09-03  2015-09-14      1  No-Recidivism           1   \n",
       "\n",
       "      c_jail_days  has_r_jail_in  has_r_jail_out  custody_days  \n",
       "id                                                              \n",
       "2677          3.0          False           False             4  \n",
       "548          -1.0          False           False             0  \n",
       "56           79.0          False           False             1  \n",
       "489           1.0          False           False             1  \n",
       "430           1.0           True            True            11  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.drop(\n",
    "    [\"c_arrest_date\", \n",
    "    'c_charge_desc', \n",
    "    # 'days_b_screening_arrest'\n",
    "    ], axis=1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['target_int'] = train_df['target'].replace({'No-Recidivism': 0, 'Non-Violent': 1, 'Violent': 2})\n",
    "train_df['target_bool'] = train_df['target'].replace({'No-Recidivism': 0, 'Non-Violent': 1, 'Violent': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_features = [\n",
    "    'sex', 'age_group', 'race', \n",
    "    'days_b_screening_arrest',\n",
    "    'c_charge_degree',\n",
    "    # 'c_charge_desc',\n",
    "    'start', 'all_priors',\n",
    "    'c_jail_days', 'has_r_jail_in', 'has_r_jail_out', 'custody_days'\n",
    "]\n",
    "\n",
    "cat_features = ['sex', \"age_group\", 'race', 'c_charge_degree', 'has_r_jail_in', 'has_r_jail_out']\n",
    "\n",
    "train_df[training_features].head()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(train_df.index, train_df.days_b_screening_arrest)\n",
    "plt.ylabel('days_b_screening_arrest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 - score: 0.7915 - roc: 0.5587\n",
      "epoch: 2 - score: 0.8004 - roc: 0.5226\n",
      "epoch: 3 - score: 0.7935 - roc: 0.4397\n",
      "epoch: 4 - score: 0.7895 - roc: 0.4475\n",
      "epoch: 5 - score: 0.7974 - roc: 0.5452\n",
      "epoch: 6 - score: 0.7895 - roc: 0.4980\n",
      "epoch: 7 - score: 0.8004 - roc: 0.5183\n",
      "epoch: 8 - score: 0.7945 - roc: 0.4512\n",
      "epoch: 9 - score: 0.7935 - roc: 0.5100\n",
      "epoch: 10 - score: 0.7945 - roc: 0.5101\n",
      "epoch: 11 - score: 0.8113 - roc: 0.5201\n",
      "epoch: 12 - score: 0.7836 - roc: 0.4765\n",
      "epoch: 13 - score: 0.7925 - roc: 0.4986\n",
      "epoch: 14 - score: 0.7935 - roc: 0.4872\n",
      "epoch: 15 - score: 0.7915 - roc: 0.4915\n",
      "epoch: 16 - score: 0.7964 - roc: 0.4753\n",
      "epoch: 17 - score: 0.7866 - roc: 0.4727\n",
      "epoch: 18 - score: 0.7945 - roc: 0.4984\n",
      "epoch: 19 - score: 0.7974 - roc: 0.5512\n",
      "epoch: 20 - score: 0.7974 - roc: 0.5462\n",
      "epoch: 21 - score: 0.7974 - roc: 0.5075\n",
      "epoch: 22 - score: 0.7915 - roc: 0.5656\n",
      "epoch: 23 - score: 0.7875 - roc: 0.4057\n",
      "epoch: 24 - score: 0.7905 - roc: 0.4802\n",
      "epoch: 25 - score: 0.8053 - roc: 0.5088\n",
      "epoch: 26 - score: 0.8103 - roc: 0.5010\n",
      "epoch: 27 - score: 0.7856 - roc: 0.5153\n",
      "epoch: 28 - score: 0.7925 - roc: 0.4993\n",
      "epoch: 29 - score: 0.7955 - roc: 0.4611\n",
      "epoch: 30 - score: 0.7885 - roc: 0.5633\n",
      "epoch: 31 - score: 0.7875 - roc: 0.5098\n",
      "epoch: 32 - score: 0.8073 - roc: 0.5127\n",
      "epoch: 33 - score: 0.7935 - roc: 0.5128\n",
      "epoch: 34 - score: 0.7895 - roc: 0.4130\n",
      "epoch: 35 - score: 0.7945 - roc: 0.4736\n",
      "epoch: 36 - score: 0.7955 - roc: 0.5099\n",
      "epoch: 37 - score: 0.7955 - roc: 0.4751\n",
      "epoch: 38 - score: 0.7935 - roc: 0.4817\n",
      "epoch: 39 - score: 0.7974 - roc: 0.5054\n",
      "epoch: 40 - score: 0.7905 - roc: 0.5387\n",
      "epoch: 41 - score: 0.7984 - roc: 0.4344\n",
      "epoch: 42 - score: 0.7885 - roc: 0.5279\n",
      "epoch: 43 - score: 0.8014 - roc: 0.4363\n",
      "epoch: 44 - score: 0.7895 - roc: 0.4433\n",
      "epoch: 45 - score: 0.7945 - roc: 0.5259\n",
      "epoch: 46 - score: 0.7875 - roc: 0.5304\n",
      "epoch: 47 - score: 0.8053 - roc: 0.5042\n",
      "epoch: 48 - score: 0.7935 - roc: 0.5198\n",
      "epoch: 49 - score: 0.7935 - roc: 0.5220\n",
      "epoch: 50 - score: 0.7925 - roc: 0.4136\n",
      "[[0.7923 0.1711 0.0366]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7926 0.1708 0.0366]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7926 0.1708 0.0366]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7925 0.1709 0.0365]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7924 0.1711 0.0366]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7926 0.1708 0.0366]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7924 0.1711 0.0366]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7924 0.1711 0.0366]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7924 0.1711 0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7924 0.171  0.0365]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7926 0.1708 0.0366]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7924 0.1711 0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7924 0.1711 0.0366]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7924 0.1711 0.0366]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7925 0.1709 0.0365]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7925 0.1709 0.0365]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7924 0.1711 0.0366]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7926 0.1709 0.0366]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7924 0.171  0.0366]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7925 0.1709 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7924 0.1711 0.0365]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7927 0.1708 0.0365]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7924 0.1711 0.0366]\n",
      " [0.7926 0.1709 0.0365]\n",
      " [0.7926 0.1708 0.0365]\n",
      " [0.7923 0.1711 0.0366]\n",
      " [0.7925 0.171  0.0366]\n",
      " [0.7924 0.171  0.0366]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "X_split = train_df\n",
    "y_split = train_df.race\n",
    "epoch = 0\n",
    "\n",
    "for train_idx, val_idx in rskf.split(X_split, y_split):\n",
    "\n",
    "    X_train = X_split.iloc[train_idx].reset_index(drop=True)\n",
    "    X_val = X_split.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    training_set = X_train[training_features]\n",
    "    training_target = X_train.target_int\n",
    "\n",
    "    validation_set = X_val[training_features]\n",
    "    validation_target = X_val.target_int\n",
    "\n",
    "    # encode dataset\n",
    "    encoder = ColumnTransformer(\n",
    "        [(\"OneHotEncoder\", OneHotEncoder(), cat_features)],\n",
    "        remainder='passthrough'\n",
    "    ).fit(training_set)\n",
    "    \n",
    "    training_set = encoder.transform(training_set)\n",
    "    validation_set = encoder.transform(validation_set)\n",
    "\n",
    "#     normalize dataset\n",
    "    normalizer = Normalizer().fit(training_set)\n",
    "    \n",
    "    training_set = normalizer.transform(training_set)\n",
    "    validation_set = normalizer.transform(validation_set)\n",
    "\n",
    "    # fit model\n",
    "#     model = OneVsOneClassifier(\n",
    "    model = LogisticRegressionCV(random_state=0, max_iter=1000)\n",
    "        # LinearSVC(random_state=0, max_iter=10000)\n",
    "#     )\n",
    "    \n",
    "    model.fit(training_set, training_target)\n",
    "\n",
    "    prediction = model.predict(validation_set)\n",
    "    prediction_proba = model.predict_proba(validation_set)\n",
    "#     decision_func = model.decision_function(validation_set)\n",
    "    score = model.score(training_set, training_target)\n",
    "    roc = roc_auc_score(validation_target, prediction_proba, multi_class=\"ovo\")\n",
    "    \n",
    "\n",
    "    epoch += 1\n",
    "    print(f\"epoch: {epoch} - score: {score:.4f} - roc: {roc:.4f}\")\n",
    "\n",
    "print(np.round(prediction_proba, decimals=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_race = {}\n",
    "\n",
    "races = []\n",
    "race_validation_set = validation_set[[]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
